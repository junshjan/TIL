# 신경망

#### 1.1 신경망의 예

신경망의 0층은 입력층, 1층은 은닉층, 2층은 출력층이다

#### 1.2 퍼셉트론

퍼셉트론은
$$
y = h(b+w_1x_1 + w_2x_2)\\
h(x)= \begin{Bmatrix}0(x  \leq0)\\1(x>0)\\ \end{Bmatrix}
$$
이 두개의 식으로 나눠서 표현할 수 있다.

#### 1.3 활성화 함수

<img src= "https://media.vlpt.us/images/joo4438/post/a2d53cc7-446e-419e-a740-b407d26f617b/image.png ">

위 그림은 활성화 함수 처리과정

___

## 2. 활성화 함수

+ 퍼셉트론에서는 활성화 함수로 계단함수를 사용함

#### 2.1 시그모이드 함수

$$
h(x) = \frac{1}{1+exp(-x)}
$$

위 식은 신경망에서 자주 이용하는 시그모이드 함수의 식이다

+ exp(-x)는 

